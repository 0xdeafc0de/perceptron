# single-layer-perceptron
A perceptron is a fundamental building block of artificial intelligence and machine learning.
Think of it as a simplified model of a neuron in our brain. It takes inputs, multiplies them by their respective weights, adds them up, and applies a threshold to determine its output.

This output is then compared to the desired output (target), and the perceptron adjusts its weights using a process called gradient descent to minimize the difference between the actual and desired outputs. In essence, the perceptron learns from data to make predictions or classify new examples, just as we, humans, learn to make decisions in our daily lives.

This, minimal single-layer perceptron example is a great fit for educating ML from ground-up and serves as a foundation for more complex models.

## Key Features
- Represents a single neuron with 3 inputs
- Trains using a simplified rule (gradient update without full error propagation)
- Uses sigmod activation function
- Trained on synthetic training data and test evaluation
- Goal - To learn 'x1 AND x2 (ignoring x3)'


